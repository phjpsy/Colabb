{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SKT_OpenNMT_Pytorch_실습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phjpsy/Colabb/blob/master/SKT_OpenNMT_Pytorch_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpgq2KISOHBo",
        "colab_type": "text"
      },
      "source": [
        "# OpenNMT Pytorch를 이용한 기계번역 모델 만들어보기\n",
        "\n",
        "***First Go to Runtime and  change the runtime type to GPU.***\n",
        "\n",
        "\n",
        "<br>\n",
        " Copyright Park Chanjun\n",
        "<br>\n",
        " Email: bcj1210@naver.com\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKeg7ElS3qOQ",
        "colab_type": "text"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKrzegS2O1t3",
        "colab_type": "text"
      },
      "source": [
        "# Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-kDi11Xx5bs",
        "colab_type": "code",
        "outputId": "22e391fb-25d2-4888-ffc4-a7b8033a245e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OpenNMT-py'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 15541 (delta 3), reused 2 (delta 1), pack-reused 15529\u001b[K\n",
            "Receiving objects: 100% (15541/15541), 146.48 MiB | 14.50 MiB/s, done.\n",
            "Resolving deltas: 100% (11189/11189), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnGauLA9U0g",
        "colab_type": "code",
        "outputId": "923519ed-8b1c-4bc0-f47e-e5295d610ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OpenNMT-py  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TlIyXGzO61s",
        "colab_type": "text"
      },
      "source": [
        "# 환경설정\n",
        "\n",
        "> Error : You must restart the runtime in order to use newly installed versions.<br>\n",
        "Solution : Click Restart Runtime => Redo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gq-o1qtyFR0",
        "colab_type": "code",
        "outputId": "0202224b-725e-4648-aa13-6ddef357b258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!pip install OpenNMT-py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.16.0)\n",
            "Requirement already satisfied: torchtext==0.4.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.4.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.4.3)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.15.0)\n",
            "Requirement already satisfied: pyonmttok==1.*; platform_system == \"Linux\" in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.18.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.1.1)\n",
            "Requirement already satisfied: tqdm~=4.30.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (4.30.0)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0->OpenNMT-py) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0->OpenNMT-py) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (45.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.27.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (2.11.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (7.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (2019.11.28)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_4ZgPbp71Eb",
        "colab_type": "text"
      },
      "source": [
        "# 기계번역 모델 만드는 순서\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**1.   데이터 수집**\n",
        "\n",
        "병렬 코퍼스를 수집해야합니다.\n",
        "이번 실습에서는 OpenNMT에서 제공하는 WMT 데이터를 사용합니다.\n",
        "\n",
        "**2.   정제, 병렬 코퍼스 필터링**\n",
        "\n",
        "병렬 코퍼스 필터링 (생략)\n",
        "\n",
        "\n",
        "**3. 서브워드 분리**\n",
        "\n",
        "BPE를 사용\n",
        "\n",
        "\n",
        "**4. 학습**\n",
        "\n",
        "GPU를 이용한 Transformer 훈련\n",
        "\n",
        "\n",
        "**5. 번역**\n",
        "\n",
        "모델을 이용한 번역\n",
        "\n",
        "\n",
        "**6. Detokenization**\n",
        "\n",
        "디토큰\n",
        "\n",
        "\n",
        "**7. 점수계산**\n",
        "\n",
        "BLEU 점수 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTBNfRgW-WvJ",
        "colab_type": "text"
      },
      "source": [
        "# Subword Tokenization\n",
        "\n",
        "We use Byte Pair Encoding for Subword Tokenization\n",
        "\n",
        "https://www.aclweb.org/anthology/P16-1162\n",
        "\n",
        "i => input<br>\n",
        "o ==> Output(*.code)<br>\n",
        "s ==> Symbol<br>\n",
        "\n",
        "learn_bpe ==> make code<br>\n",
        "apply_bpe ==> apply subwordTokenization<br>\n",
        "\n",
        "src-train, src-val,test ==> Need to apply src.code<br>\n",
        "tgt-train,tgt-val ==> Need to apply tgt.code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASorEhAu-kdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/learn_bpe.py -i OpenNMT-py/data/src-train.txt -o OpenNMT-py/data/src.code -s 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBNAu8tR_GcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/learn_bpe.py -i OpenNMT-py/data/tgt-train.txt -o OpenNMT-py/data/tgt.code -s 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB5FdD-H_H59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-train.txt -o OpenNMT-py/data/src-train-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaherUkX_IBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-val.txt -o OpenNMT-py/data/src-val-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz7Xu72Y_mWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-test.txt -o OpenNMT-py/data/src-test-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSGaSYgq_nmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i OpenNMT-py/data/tgt-train.txt -o OpenNMT-py/data/tgt-train-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7n68i95_nuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i OpenNMT-py/data/tgt-val.txt -o OpenNMT-py/data/tgt-val-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FknMbLeePeoQ",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocess the data**\n",
        "\n",
        "We will be working with some example data in data/ folder.\n",
        "\n",
        "The data consists of parallel source (src) and target (tgt) data containing one sentence per line with tokens separated by a space:\n",
        "\n",
        "1. src-train.txt\n",
        "\n",
        "2. tgt-train.txt\n",
        "\n",
        "3. src-val.txt\n",
        "\n",
        "4. tgt-val.txt\n",
        "\n",
        "\n",
        "Train data and validataion data are required for machine translation training.\n",
        "\n",
        "Validation files are required and used to evaluate the convergence of the training. It usually contains no more than 5000 sentences.\n",
        "\n",
        "\n",
        "> If you think about it briefly, you can specify the path of train data and validation data, and specify the path and name to save in -save_data.\n",
        "\n",
        "> If you want to set vocab size add below command\n",
        "<br>\n",
        "-src_vocab_size 32000 -tgt_vocab_size 32000\n",
        "\n",
        "The vocab size is usually 32000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DrdI_6l0Kvw",
        "colab_type": "code",
        "outputId": "a6e2cad3-3c1d-4748-b5c3-234e7b6129ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!python OpenNMT-py/preprocess.py -train_src OpenNMT-py/data/src-train-bpe.txt -train_tgt OpenNMT-py/data/tgt-train-bpe.txt -valid_src OpenNMT-py/data/src-val-bpe.txt -valid_tgt OpenNMT-py/data/tgt-val-bpe.txt -save_data OpenNMT-py/data/demo -src_vocab_size 32000 -tgt_vocab_size 32000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-03-05 14:07:35,756 INFO] Extracting features...\n",
            "[2020-03-05 14:07:35,756 INFO]  * number of source features: 0.\n",
            "[2020-03-05 14:07:35,756 INFO]  * number of target features: 0.\n",
            "[2020-03-05 14:07:35,756 INFO] Building `Fields` object...\n",
            "[2020-03-05 14:07:35,757 INFO] Building & saving training data...\n",
            "[2020-03-05 14:07:35,798 INFO] Building shard 0.\n",
            "[2020-03-05 14:07:36,311 INFO]  * saving 0th train data shard to OpenNMT-py/data/demo.train.0.pt.\n",
            "[2020-03-05 14:07:37,031 INFO]  * tgt vocab size: 10034.\n",
            "[2020-03-05 14:07:37,046 INFO]  * src vocab size: 9739.\n",
            "[2020-03-05 14:07:37,109 INFO] Building & saving validation data...\n",
            "[2020-03-05 14:07:37,164 INFO] Building shard 0.\n",
            "[2020-03-05 14:07:37,239 INFO]  * saving 0th valid data shard to OpenNMT-py/data/demo.valid.0.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8wQov27R004",
        "colab_type": "text"
      },
      "source": [
        "# **Train the data(Transformer)**\n",
        "\n",
        "https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf\n",
        "\n",
        "\n",
        "> If you get GPU-related errors, try halving batch_size\n",
        "\n",
        "**Below is the full command, and if you want to know more about it, search about Transformer.**\n",
        "\n",
        "!python OpenNMT-py/train.py -data OpenNMT-py/data/demo -save_model OpenNMT-py/data/model/model -layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 -encoder_type transformer -decoder_type transformer -position_encoding -train_steps 200000 -max_generator_batches 2 -dropout 0.1 -batch_size 4096 -batch_type tokens -normalization tokens -accum_count 2 -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 -param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 -world_size 1 -gpu_rank 0  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH1fS8F2VAuz",
        "colab_type": "code",
        "outputId": "b4df7521-c1ef-4fee-f906-229c404c11be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar  5 14:08:57 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdTjS0bTSVLk",
        "colab_type": "code",
        "outputId": "69950e7e-de49-4559-866d-9ff225354857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python OpenNMT-py/train.py -data OpenNMT-py/data/demo -save_model OpenNMT-py/data/model/model -layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 -encoder_type transformer -decoder_type transformer -position_encoding -train_steps 200000 -max_generator_batches 2 -dropout 0.1 -batch_size 4096 -batch_type tokens -normalization tokens -accum_count 2 -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 -param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 -world_size 1 -gpu_rank 0  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-03-05 14:09:22,642 INFO]  * src vocab size = 9739\n",
            "[2020-03-05 14:09:22,642 INFO]  * tgt vocab size = 10034\n",
            "[2020-03-05 14:09:22,642 INFO] Building model...\n",
            "[2020-03-05 14:09:31,881 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(9739, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10034, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=10034, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-03-05 14:09:31,892 INFO] encoder: 23901696\n",
            "[2020-03-05 14:09:31,892 INFO] decoder: 35510066\n",
            "[2020-03-05 14:09:31,892 INFO] * number of parameters: 59411762\n",
            "[2020-03-05 14:09:31,901 INFO] Starting training on GPU: [0]\n",
            "[2020-03-05 14:09:31,901 INFO] Start training loop and validate every 1000 steps...\n",
            "[2020-03-05 14:09:31,902 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2020-03-05 14:09:32,016 INFO] number of examples: 8868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMf27BpGWpn7",
        "colab_type": "text"
      },
      "source": [
        "# **Translate**\n",
        "\n",
        "Now that you have your model, you can start translating.\n",
        "\n",
        "-model ==> Setting your model\n",
        "\n",
        "Output predictions into pred.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqz9Iu7pW4Bq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9377429b-cbfe-4136-90c5-9c4b2382e7ef"
      },
      "source": [
        "!python OpenNMT-py/translate.py -model OpenNMT-py/data/model/model_step_1000.pt -src OpenNMT-py/data/src-val.txt -output OpenNMT-py/data/pred.txt -replace_unk -verbose -gpu 0 -beam_size 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'OpenNMT-py/translate.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjG2ILxtGQ5U",
        "colab_type": "text"
      },
      "source": [
        "# Detokenization\n",
        "\n",
        "Even after the translation process is finished, it is still in a segment, so it is different from the actual sentence structure used by real people. Thus, when you perform a detoxification process, it is returned in the form of the actual sentence.\n",
        "\n",
        "We Use \"sed\" for BPE Detokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74sox8UmGcbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -i \"s/@@ //g\"  OpenNMT-py/data/pred.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCHeu1YFGngg",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Using BLEU\n",
        "\n",
        "Quantitative evaluation is performed on the sentence thus obtained. BLEU is a quantitative evaluation method for machine translation. You can see which model is superior by comparing it to the BLEU score you are comparing.\n",
        "\n",
        "https://www.aclweb.org/anthology/P02-1040"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gpcnSSTG0Kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!perl  OpenNMT-py/tools/multi-bleu.perl OpenNMT-py/data/tgt-val.txt < OpenNMT-py/data/pred.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfAgvxNCXTo6",
        "colab_type": "text"
      },
      "source": [
        "If you have Any Question Please Email to  \"bcj1210@naver.com\""
      ]
    }
  ]
}